{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dffcb487fa0f84b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T22:19:14.780299Z",
     "start_time": "2025-09-18T22:19:14.777942Z"
    }
   },
   "source": [
    "## Wikipedia Retriever"
   ]
  },
  {
   "cell_type": "code",
   "id": "eb980281b3ee5f88",
   "metadata": {},
   "source": [
    "!pip install langchain chromadb faiss-cpu openai tiktoken langchain_openai langchain-community wikipedia"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e3b8ee905c18805a",
   "metadata": {},
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "db55ee8dbdcbc3d8",
   "metadata": {},
   "source": [
    "# Initialize the retriever (optional: set language and top_k)\n",
    "retriever = WikipediaRetriever(top_k_results=2, lang=\"en\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b0613de8143b3db",
   "metadata": {},
   "source": [
    "# Define your query\n",
    "query = \"the geopolitical history of india and pakistan from the perspective of a chinese\"\n",
    "\n",
    "# Get relevant Wikipedia documents\n",
    "docs = retriever.invoke(query)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3c2bf8a0e92ff667",
   "metadata": {},
   "source": [
    "docs"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fc37abfeff21b3ad",
   "metadata": {},
   "source": [
    "# Print retrieved content\n",
    "for i, doc in enumerate(docs):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(f\"Content:\\n{doc.page_content}...\")  # truncate for display"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1d262134299f324",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-18T22:45:20.433837Z",
     "start_time": "2025-09-18T22:45:20.432029Z"
    }
   },
   "source": [
    "## Vector Store Retriever"
   ]
  },
  {
   "cell_type": "code",
   "id": "3538b4c4eafa34d9",
   "metadata": {},
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a54cc2c60291076e",
   "metadata": {},
   "source": [
    "# Step 1: Your source documents\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain helps developers build LLM applications easily.\"),\n",
    "    Document(page_content=\"Chroma is a vector database optimized for LLM-based search.\"),\n",
    "    Document(page_content=\"Embeddings convert text into high-dimensional vectors.\"),\n",
    "    Document(page_content=\"OpenAI provides powerful embedding models.\"),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ca63f1b994167555",
   "metadata": {},
   "source": [
    "# Step 2: Initialize embedding model\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 3: Create Chroma vector store in memory\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    collection_name=\"my_collection\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe987b8ee6c6691b",
   "metadata": {},
   "source": [
    "# Step 4: Convert vectorstore into a retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 2})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "134fd74b4831cf60",
   "metadata": {},
   "source": [
    "query = \"What is Chroma used for?\"\n",
    "results = retriever.invoke(query)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "31b8284035d4dfd1",
   "metadata": {},
   "source": [
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ad0344a3c7b31a13",
   "metadata": {},
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1cef4094cd87d3e2",
   "metadata": {},
   "source": [
    "results = vectorstore.similarity_search(query, k=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b1fd2647436ed2c1",
   "metadata": {},
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "afad6de31dc4cd58",
   "metadata": {},
   "source": [
    "## MMR - Maximal Marginal Relevance"
   ]
  },
  {
   "cell_type": "code",
   "id": "7e4e8a527886fa99",
   "metadata": {},
   "source": [
    "# Sample documents\n",
    "docs = [\n",
    "    Document(page_content=\"LangChain makes it easy to work with LLMs.\"),\n",
    "    Document(page_content=\"LangChain is used to build LLM based applications.\"),\n",
    "    Document(page_content=\"Chroma is used to store and search document embeddings.\"),\n",
    "    Document(page_content=\"Embeddings are vector representations of text.\"),\n",
    "    Document(page_content=\"MMR helps you get diverse results when doing similarity search.\"),\n",
    "    Document(page_content=\"LangChain supports Chroma, FAISS, Pinecone, and more.\"),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5d5cfebf0686ee0d",
   "metadata": {},
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Step 2: Create the FAISS vector store from documents\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_model\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64c9f92183074da2",
   "metadata": {},
   "source": [
    "# Enable MMR in the retriever\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"mmr\",                   # <-- This enables MMR\n",
    "    search_kwargs={\"k\": 3, \"lambda_mult\": 0.5}  # k = top results, lambda_mult = relevance-diversity balance\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dcf282628e97bb32",
   "metadata": {},
   "source": [
    "query = \"What is langchain?\"\n",
    "results = retriever.invoke(query)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9a50935fd3d195e",
   "metadata": {},
   "source": [
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dc0d0858ab589004",
   "metadata": {},
   "source": [
    "## Multiquery Retriever"
   ]
  },
  {
   "cell_type": "code",
   "id": "97d9e913c839bbaf",
   "metadata": {},
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4f3797d510538c0",
   "metadata": {},
   "source": [
    "# Relevant health & wellness documents\n",
    "all_docs = [\n",
    "    Document(page_content=\"Regular walking boosts heart health and can reduce symptoms of depression.\", metadata={\"source\": \"H1\"}),\n",
    "    Document(page_content=\"Consuming leafy greens and fruits helps detox the body and improve longevity.\", metadata={\"source\": \"H2\"}),\n",
    "    Document(page_content=\"Deep sleep is crucial for cellular repair and emotional regulation.\", metadata={\"source\": \"H3\"}),\n",
    "    Document(page_content=\"Mindfulness and controlled breathing lower cortisol and improve mental clarity.\", metadata={\"source\": \"H4\"}),\n",
    "    Document(page_content=\"Drinking sufficient water throughout the day helps maintain metabolism and energy.\", metadata={\"source\": \"H5\"}),\n",
    "    Document(page_content=\"The solar energy system in modern homes helps balance electricity demand.\", metadata={\"source\": \"I1\"}),\n",
    "    Document(page_content=\"Python balances readability with power, making it a popular system design language.\", metadata={\"source\": \"I2\"}),\n",
    "    Document(page_content=\"Photosynthesis enables plants to produce energy by converting sunlight.\", metadata={\"source\": \"I3\"}),\n",
    "    Document(page_content=\"The 2022 FIFA World Cup was held in Qatar and drew global energy and excitement.\", metadata={\"source\": \"I4\"}),\n",
    "    Document(page_content=\"Black holes bend spacetime and store immense gravitational energy.\", metadata={\"source\": \"I5\"}),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "bd1773c6bfc9258c",
   "metadata": {},
   "source": [
    "# Initialize OpenAI embeddings\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(documents=all_docs, embedding=embedding_model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "17b76d58c1805d4f",
   "metadata": {},
   "source": [
    "# Create retrievers\n",
    "similarity_retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 5})"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe40cc1430c787a6",
   "metadata": {},
   "source": [
    "multiquery_retriever = MultiQueryRetriever.from_llm(\n",
    "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 5}),\n",
    "    llm=ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6792f222",
   "metadata": {},
   "source": [
    "# Query\n",
    "query = \"How to improve energy levels and maintain balance?\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Retrieve results\n",
    "similarity_results = similarity_retriever.invoke(query)\n",
    "multiquery_results= multiquery_retriever.invoke(query)"
   ],
   "id": "cf3356129161ed81",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(similarity_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)\n",
    "\n",
    "print(\"*\"*150)\n",
    "\n",
    "for i, doc in enumerate(multiquery_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "id": "37c5c63bbcddd7ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## ContextualCompressionRetriever:",
   "id": "e8576aba6bbe4999"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.documents import Document"
   ],
   "id": "206451b1bcee5826",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Recreate the document objects from the previous data\n",
    "docs = [\n",
    "    Document(page_content=(\n",
    "        \"\"\"The Grand Canyon is one of the most visited natural wonders in the world.\n",
    "        Photosynthesis is the process by which green plants convert sunlight into energy.\n",
    "        Millions of tourists travel to see it every year. The rocks date back millions of years.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc1\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"In medieval Europe, castles were built primarily for defense.\n",
    "        The chlorophyll in plant cells captures sunlight during photosynthesis.\n",
    "        Knights wore armor made of metal. Siege weapons were often used to breach castle walls.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc2\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"Basketball was invented by Dr. James Naismith in the late 19th century.\n",
    "        It was originally played with a soccer ball and peach baskets. NBA is now a global league.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc3\"}),\n",
    "\n",
    "    Document(page_content=(\n",
    "        \"\"\"The history of cinema began in the late 1800s. Silent films were the earliest form.\n",
    "        Thomas Edison was among the pioneers. Photosynthesis does not occur in animal cells.\n",
    "        Modern filmmaking involves complex CGI and sound design.\"\"\"\n",
    "    ), metadata={\"source\": \"Doc4\"})\n",
    "]"
   ],
   "id": "2342ccc167ae4cee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create a FAISS vector store from the documents\n",
    "embedding_model = OpenAIEmbeddings()\n",
    "vectorstore = FAISS.from_documents(docs, embedding_model)"
   ],
   "id": "c4701e9cbba304da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})",
   "id": "72e70beccf6a63e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set up the compressor using an LLM\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ],
   "id": "26f68aef3d83ad11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create the contextual compression retriever\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")"
   ],
   "id": "fa008d64ed964a71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Query the retriever\n",
    "query = \"What is photosynthesis?\"\n",
    "compressed_results = compression_retriever.invoke(query)"
   ],
   "id": "3281afd764049ec0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i, doc in enumerate(compressed_results):\n",
    "    print(f\"\\n--- Result {i+1} ---\")\n",
    "    print(doc.page_content)"
   ],
   "id": "a2cf50e2d49a4f3a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
